---
title: "Homework 2"
author: "Charandeep Grewal 301190855, James Hopkins 301139318, Alisha McGrath 301242597"
date: '2017-10-04'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Question 1 (Chapter 3, #3, 6 marks)


(a) X3 is gender and X5 is the interation between gender and GPA because βˆ 3 = 35 and βˆ 5 = − 10 a higher GPA will cause being a female to be disadvantageous therefore point "iii" is correct. When GPA is over 3.5, males make more money. Being female means that females make 35 thousand dollars more just for being a female, but make 10 thousand per 1.0 in GPA increase. This suggests that if the GPA is 3.5 then the effect of gender is neutral and any higher it is advantageous to be a man. 

(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.
```{r}
50 + 20*4 + 0.07*110 + 35*1 + 0.01*(110)*(4) - 10*(1)*(4)
```
137100 dollars

(c) False, the effect may be small, but that does not mean that the p value for this interaction is small. We may choose to leave this effect out for parsimony's sake however. Also, since the range of IQ values is larger than both gender and GPA, the IQ coefficients will tend to be smaller anyways. 


## Question 2 (Chapter 3, #9, 10 marks)

```{r}
library(ISLR) 
data(Auto)
library(dplyr)
Auto2 <- Auto %>% select(-name) %>% mutate(origin = factor(origin))
head(Auto)
head(Auto2)
```
(a) P
```{r}
pairs(Auto)
```

(b) 
```{r}

AutoCor <- Auto2[, c(1:7)]
Auto2[8] <- lapply(Auto2[8], as.numeric)
corcoefs <- cor(Auto2)
corcoefs


```
(c) 
```{r}
autolm <-lm(mpg ~ ., data = Auto2)
summary(autolm)
```

i. Yes there is a relationship between the predictors and the response, the F statistic is very large. The p values for cylinders, acceleration, and horsepower are very large and suggest that there is no relationship between them and mpg.

ii. Weight, year, origin, and displacement are statistically significant. 

iii. The year coefficient is very statistically significant (very small p value). It suggests that for every year newer a car is, its mpg increases by 0.751. 

(d) 
```{r}
plot(autolm)
```
The residual vs fitted plot looks mostly linear, but there may be a slight dip in the middle. There appears to be non-constant error variance due to the funnel shape of the Residuals vs Fitted plot. Observation 14 has a very high amount of leverage. 321, 325, and 324 may be outliers.

(e) 
```{r}
autolm2 <-lm(mpg ~ (.)^2, data = Auto2)
summary(autolm2)


Auto2$acceleration <- NULL
Auto2$horsepower <- NULL
autolm3 <-lm(mpg ~ (.)^2, data = Auto2) 

summary(autolm3)
```
The interactions: acceleration:year, acceleration:origin, displacement:year all appear to have significant interaction effects at the 5% level when every predictor is included. 

(f)
```{r}

plot(lm(mpg~ weight+displacement+year+origin, data = Auto))
plot(lm (mpg~ log(weight)+displacement+year+origin, data = Auto))
plot(lm(mpg~ sqrt(weight)+displacement+year+origin, data = Auto))
plot(lm(mpg~ weight + I(weight^2)+displacement+year+origin, data = Auto))
```
Both log(weight) and the addition of weight^2 seem to fit the data slightly better, however all transformations suffer from similar problems. 


```{r}
fit.weight1 = lm(mpg~displacement+weight+year+origin, data=Auto)
fit.weight2 = lm(mpg~displacement+I(weight^2)+year+origin, data=Auto)
fit.weight3 = lm(mpg~displacement+log(weight)+year+origin, data=Auto)
fit.displacement = lm(mpg~I(displacement^2)+weight+year+origin, data=Auto)
summary(fit.weight1)
summary(fit.weight2)
summary(fit.weight3)
summary(fit.displacement)
```

Looking at the summaries, weight^2 and log(weight) both improve the p-values of all the predictors, but weight^2 does a better job reducing the p-values. When looking at those two summaries, the displacement predictor is still doesn't reach the threshold p-value for significance. Trasnforming displacement by squaring it, causes all predictors to have a p-value below 0.05, allowing them to be significant. Squaring the displacement seems to be the best model out of the ones we tested. 


## Question 3 (Chapter 4, #4, 7 marks)

(a) (0.65-0.55)/(1-0) = 10% of the available observations due to 'X' being uniformly distributed. 

(b) Since both X1 and X2 are using 10% of the available observations and 'X' is also uniformaly distributed, then: 0.1*0.1 = 0.01 or 1 % of the available observations. 

(c) Given (a) and (b), for 100 features only $0.1^{100}$ observations would be used. 

(d) Given parts a-c, as you start to increase the number of features, a lower percentage of available observations are used when using the KNN method. This means that for a given sample size, more feaures = fewer neighbours. In (a), 1 feature is used which allows us to use 10% of the available observations. In (c), when 100 features are used the percentage of observations used is extremely small. Also, due to the 'curse of dimensionality' the test may not have any nearby neighbours when the number of features is large, leading to poor predictions.  

(e) For p = 1 : $0.1^{1}=$ 0.1,  for p = 2: $0.1^{1/2}=$ 0.316,  for p = 100: $0.1^{1/100}=$ 0.977 --> This means for p = 1 we would need to use 10% of that feature's range to get 10% of the training observations. For p = 2, we would have to use 31.6% of each feature's range to get 10% of the training observations. For p = 100, we would have to get 97.7% of each feaure's range to cover 10% of the training observations. When number of features is increased , the percentage of observations in each feature's range to get 10% of the training observations is also increased. In the p = 100 case, we can see that we would need almost the entire range of each feature's observations just to cover 10% of the training observations.


## Question 4 (Chapter 4, #10 parts (a)-(h), 9 marks)

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i) DO NOT HAND IN THIS PART (though you are, of course,
free to do it on your own).