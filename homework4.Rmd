---
title: "Homework 4"
author: "Charandeep Grewal 301190855, James Hopkins 301139318, Alisha McGrath 301242597"
date: '2017-11-15'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Question 1 (Chapter 8, #11, 9 marks)


## Question 1 (Chapter 8, #11, 9 marks)




```{r}
library(ISLR)
attach(Caravan)
set.seed(1)


```

a) Create a training set consisting of the first 1,000 observations,
and a test set consisting of the remaining observations.
```{r}
Car <- Caravan
levels(Car$Purchase)
levels(Car$Purchase) <- c("0", "1")
train <- Car[1:1000,]
test <- Car[1001:nrow(Car),]
```


(b) Fit a boosting model to the training set with Purchase as the
response and the other variables as predictors. Use 1,000 trees,
and a shrinkage value of 0.01. Which predictors appear to be
the most important?

```{r}
library(gbm)
set.seed(1)

boosted = gbm(Purchase~., data=train, n.trees=1000, shrinkage=0.01, distribution="gaussian")
boosted
```
“PPERSAUT” and “MKOOPKLA” are the most important

(c) Use the boosting model to predict the response on the test data.
Predict that a person will make a purchase if the estimated probability
of purchase is greater than 20 %. Form a confusion matrix.
What fraction of the people predicted to make a purchase
do in fact make one? How does this compare with the results
obtained from applying KNN or logistic regression to this data
set?

```{r}
pred <- predict(boosted, test, n.trees = 1000,type = "link")

#pred <- exp(pred)/(1+exp(pred))
predictions <- ifelse(pred > 1.2, 1, 0)
table(test$Purchase, predictions)
11/(11+40)

logreg <- glm(Purchase ~ ., data = train, family = "binomial")
logpredict <- predict(logreg, test,type="response")
logpred <-ifelse(logpredict > 0.2, 1, 0)
table(test$Purchase, logpred)

58/(58+350)



```
The fraction of purchases that are predicted that were really purchases is 0.216 for the boosting model and 0.142 for the logistic regression model.

## Question 2 (Ch9, #7, 11 marks)

(a) (1 mark)
```{r}
library(ISLR)
gas.median = median(Auto$mpg)
bin.var = ifelse(Auto$mpg > gas.median, 1, 0)
Auto$binary.mpg = as.factor(bin.var)
```
(b) (3 marks)
```{r}
library(e1071)
set.seed(1994)
Auto1 = Auto[-1]
tune.out = tune(svm,binary.mpg ~ ., data = Auto1, kernel = "linear", ranges=list(cost=c(10^{-3:3})))
summary(tune.out)
```
The cross validation error is lowest when cost = 0.01. 

(c) (5 marks)
```{r}
set.seed(1994)
tune.out1 = tune(svm, binary.mpg ~ ., data = Auto1, kernel = "radial", ranges=list(cost=c(10^{-3:3}),gamma=c(0.001, 0.01, 0.1, 1:3)))
summary(tune.out1)
```
The cross validation error is lowest when cost = 10 and gamma = 0.1.
```{r}
set.seed(1994)
tune.out2 = tune(svm, binary.mpg ~ ., data = Auto1, kernel = "polynomial", ranges=list(cost=c(10^{-3:3}),degree=c(1:5)))
summary(tune.out2)
```
The cross validation error is the lowest when cost = 100 and degree = 1. 
(d) (2 marks)
```{r}
svm.linear = svm(binary.mpg~., data=Auto, kernel="linear", cost=0.01)
svm.radial = svm(binary.mpg~., data=Auto, kernel="radial", cost=10, gamma=0.1)
svm.poly = svm(binary.mpg~., data=Auto, kernel="polynomial", cost=100, degree=1)
plot(svm.linear,Auto,mpg~cylinders)
plot(svm.linear,Auto,mpg~displacement)
plot(svm.linear,Auto,mpg~horsepower)
plot(svm.linear,Auto,mpg~weight)
plot(svm.linear,Auto,mpg~acceleration)
plot(svm.linear,Auto,mpg~year)
plot(svm.linear,Auto,mpg~origin)
```
```{r}
plot(svm.radial,Auto,mpg~cylinders)
plot(svm.radial,Auto,mpg~displacement)
plot(svm.radial,Auto,mpg~horsepower)
plot(svm.radial,Auto,mpg~weight)
plot(svm.radial,Auto,mpg~acceleration)
plot(svm.radial,Auto,mpg~year)
plot(svm.radial,Auto,mpg~origin)
```
```{r}
plot(svm.poly,Auto,mpg~cylinders)
plot(svm.poly,Auto,mpg~displacement)
plot(svm.poly,Auto,mpg~horsepower)
plot(svm.poly,Auto,mpg~weight)
plot(svm.poly,Auto,mpg~acceleration)
plot(svm.poly,Auto,mpg~year)
plot(svm.poly,Auto,mpg~origin)
```
